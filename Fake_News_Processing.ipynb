{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_News_Processing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMssj6wAIUxzs4bGgceDaiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stanleykywu/Fake_News_Processing/blob/master/Fake_News_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2q6Glb-yaFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install Tensorflow\n",
        "#!pip install Keras\n",
        "#!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2COcEH54QlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W31zx90f3fBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words('english')\n",
        "\n",
        "def clean_string(str):\n",
        "  arr = np.array([word for word in str.split() if word not in stoplist])\n",
        "  y=\"\"\n",
        "  for i in range(arr.size):\n",
        "    y += arr[i] + \" \"\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPQQ9BcEsQVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Fake_News_Language_Processing/Fake.csv\", usecols=['title'])\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.7\n",
        "\n",
        "train_fake = np.array(df[msk])[:,0]\n",
        "train_fake_output = np.array([1 for i in range(train_fake.size)])\n",
        "test_fake = np.array(df[~msk])[:,0]\n",
        "test_fake_output = np.array([1 for i in range(test_fake.size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnGiaLvHspoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Fake_News_Language_Processing/True.csv\", usecols=['title'])\n",
        "df['split'] = np.random.randn(df.shape[0], 1)\n",
        "\n",
        "msk = np.random.rand(len(df)) <= 0.7\n",
        "train_true = np.array(df[msk])[:,0]\n",
        "train_true_output = np.array([0 for i in range(train_true.size)])\n",
        "test_true = np.array(df[~msk])[:,0]\n",
        "test_true_output = np.array([0 for i in range(test_true.size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghSV6tt7ssO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_string = np.append(train_fake, train_true)\n",
        "train_output = np.append(train_fake_output, train_true_output)\n",
        "\n",
        "test_string = np.append(test_fake, test_true)\n",
        "test_output = np.append(test_fake_output, test_true_output)\n",
        "\n",
        "for i in range(train_string.size):\n",
        "  train_string[i] = clean_string(train_string[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uP8t5OF8sPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing String inputs by transforming them into integers \n",
        "# by using hashing_trick\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import hashing_trick\n",
        "\n",
        "length = 750\n",
        "\n",
        "train_data = np.array([np.array(hashing_trick(train_string[i], length)) for i in range(train_string.size)])\n",
        "test_data = np.array([np.array(hashing_trick(test_string[i], length)) for i in range(test_string.size)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LakQihl_EecN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d56910a-ce28-45cf-e776-bd908efce828"
      },
      "source": [
        "flattened = np.hstack(train_data)\n",
        "most_freq = []\n",
        "for i in range(20):\n",
        "  counts = np.bincount(flattened)\n",
        "  max = np.argmax(counts)\n",
        "  # print(max)\n",
        "  most_freq.append(max)\n",
        "  x = np.array([flattened[i] != max for i in range(flattened.size)])\n",
        "  flattened = flattened[x]\n",
        "\n",
        "print(most_freq)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43, 187, 190, 612, 53, 124, 45, 222, 92, 489, 706, 589, 537, 614, 193, 154, 638, 480, 213, 260]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RDAfUOcU_6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdafe6ab-2ecf-47c7-a1b9-3287fef74739"
      },
      "source": [
        "for i in range(train_data.size):\n",
        "  x = np.array([train_data[i][j] in most_freq for j in range(train_data[i].size)])\n",
        "  train_data[i] = train_data[i][x]\n",
        "\n",
        "resized_training = np.array([np.resize(np.asarray(train_data[i]), (5)) for i in range(train_data.size)])"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 43 193 213  43 193]\n",
            "[43 43 43 43 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr5_O3dZzpPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "38acf989-fbe3-4771-8e76-074ed3f97647"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(2, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(resized_training, train_output.T, epochs=5)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "983/983 [==============================] - 1s 1ms/step - loss: 0.7192 - accuracy: 0.6246\n",
            "Epoch 2/5\n",
            "983/983 [==============================] - 1s 1ms/step - loss: 0.6074 - accuracy: 0.6719\n",
            "Epoch 3/5\n",
            "983/983 [==============================] - 1s 1ms/step - loss: 0.5882 - accuracy: 0.6919\n",
            "Epoch 4/5\n",
            "983/983 [==============================] - 1s 1ms/step - loss: 0.5788 - accuracy: 0.6976\n",
            "Epoch 5/5\n",
            "983/983 [==============================] - 1s 2ms/step - loss: 0.5704 - accuracy: 0.7024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3fb339cd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fBBjBsL8rlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tATw_bi7zz0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}